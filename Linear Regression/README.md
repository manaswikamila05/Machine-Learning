
# Linear-Regression

Modelling uses machine learning algorithms, in which the machine learns from the data just like humans learn from their experiences. Machine learning can be used heavily in the industry. Machine learning models can be classified into the following three types based on the task performed and the nature of the output:
1. **Regression**: The output variable to be predicted is a continuous variable, e.g. scores of a student
2. **Classification**: The output variable to be predicted is a categorical variable, e.g. incoming emails as spam or ham
3. **Clustering**: No predefined notion of label allocated to groups/clusters formed, e.g. customer segmentation for generating discounts.

Regression and classification fall under **supervised learning methods** – in which you have the previous years’ data with labels and you use that to build the model.

Clustering falls under **unsupervised learning methods** – in which there is no predefined notion of labels.

Regression is the most commonly used predictive analysis model.
As you can guess, accurately predicting future outcomes has applications across industries — in economics, finance, business, medicine, engineering, education and even in sports & entertainment. Given the wide range of applications and its critical importance, it will be very interesting to understand how you can build models to accurately predict future outcomes.

Broadly speaking, it is a form of predictive modelling technique which tells us the relationship between the dependent (target variable) and independent variables (predictors).

Linear regression 
- Process of estimating relationship between variables
- Explains change in dependent variable with change in predictors
- Uses: forecasing and prediction
- Shows correlation and causation. Coreelation does not imply causation
- A form of parametric regression. Data follows fixed parameters.
- Regression guarantees interpolation and not extrapolation.

In simple terms, a parametric model can be described using a finite number of parameters. For e.g., a linear regression model built using n independent variables will have exactly n ‘parameters’ (i.e., n coefficients). The entire model can be described using these n parameters.

Interpolation means using the model to predict the value of a dependent variable on the independent values that lie within the range of data you already have. Extrapolation, on the other hand, means predicting the dependent variable on the independent values that lie outside the range of the data the model was built on.
 
Two types of linear regression :
- Simple linear regression
- Multiple linear regression

## Simple Linear Regression
The most elementary type of regression model is the simple linear regression which explains the relationship between a dependent variable and one independent variable using a straight line. The straight line is plotted on the scatter plot of these two points.

## Multiple linear regression
Multiple linear regression is a statistical technique to understand the relationship between one dependent variable and several independent variables. The objective of multiple regression is to find a linear equation that can best determine the value of dependent variable Y for different values independent variables in X.
